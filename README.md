# Churn MLOps (End-to-End)

Project: end‑to‑end ML on tabular data for **customer churn prediction**, with **DVC** for data/model versioning, **MLflow** for experiment tracking, and **FastAPI** for online inference. Includes Docker for portable serving.

---

## ⭐ Highlights

* **Model**: scikit‑learn RandomForest (pipeline with imputation + one‑hot)
* **Target**: `Churn Label` (binary)
* **Threshold strategy**:

  * Recall‑first (constraint `precision ≥ 0.80`)
  * Best F1 (balanced)
* **Versioning**: DVC (data & models) with remote storage (e.g., OneDrive / GDrive)
* **Tracking**: MLflow (SQLite backend + local artifacts)
* **Serving**: FastAPI `/predict` & `/predict_many`
* **Container**: Dockerfile to run the API anywhere

---

## Repo structure 

```
churn-mlops/
├─ api/
│  └─ app.py                 # FastAPI service
├─ data/
│  ├─ raw.csv                # raw dataset (DVC tracked)
│  └─ processed.csv          # generated by preprocess stage
├─ models/
│  └─ model.pkl              # trained pipeline (DVC tracked via stage)
├─ src/
│  ├─ preprocess.py          # clean/prepare dataset → processed.csv
│  ├─ train.py               # train RF + log to MLflow
│  ├─ evaluate.py            # threshold search + save metrics json
│  └─ config.py (optional)   # constants like TARGET/BEST_THRESHOLD
├─ metrics/
│  └─ val_metrics.json       # metrics exported for DVC (auto)
├─ dvc.yaml                  # DVC pipeline (preprocess→train→evaluate)
├─ dvc.lock                  # Pipeline lock (auto)
├─ requirements.txt          # runtime deps for the API and core model
├─ Dockerfile                # container for serving
└─ README.md                 # you are here
```

---

## Setup (local dev)

Requirements: Python 3.12+, Git, DVC, MLflow, (optional) Docker Desktop.

```bash
# clone
git clone https://github.com/<your-user>/churn-mlops.git
cd churn-mlops

# venv (Windows PowerShell)
python -m venv .venv; .\.venv\Scripts\Activate.ps1
pip install -r requirements.txt

# For training/tracking locally (dev only)
pip install mlflow dvc[pydrive2]
```

> **Windows tip**: In PowerShell, use `Invoke-RestMethod` or `curl.exe` (not the `curl` alias) for API tests.

---

## Data

* Place the raw dataset at `data/raw.csv`.
* Run the pipeline (below) to generate `data/processed.csv`.

> The project expects columns from the Telco-like churn dataset. Adjust `src/preprocess.py` for your data as needed.

---

## DVC pipeline (reproducible)

Defined in `dvc.yaml` with three stages:

* **preprocess** → `data/processed.csv`
* **train** → `models/model.pkl` (+ MLflow logging)
* **evaluate** → search thresholds & write `metrics/val_metrics.json`

### Run end-to-end

```bash
dvc repro
```

### Show metrics

```bash
dvc metrics show
```

Example output (will vary):

```
Path                      f1_best.f1  ...  recall_first.threshold
metrics/val_metrics.json  0.84636     ...  0.55
```

### Remote storage (example)

```bash
# List configured remotes
dvc remote list

# Push artifacts (processed.csv, model.pkl, etc.) to remote
dvc push

# Pull artifacts from remote on a new machine
dvc pull
```

> If you previously tracked files individually with `.dvc` files, prefer letting the **pipeline own the outputs** to avoid overlap.

---

## MLflow (experiment tracking)

We recommend a local server with SQLite backend.

### Start MLflow server

```bash
mlflow server \
  --host 127.0.0.1 --port 5000 \
  --backend-store-uri sqlite:///mlflow.db \
  --default-artifact-root ./mlruns
```

Open: [http://127.0.0.1:5000](http://127.0.0.1:5000)

### Train with logging

`src/train.py` sets:

```python
mlflow.set_tracking_uri("http://127.0.0.1:5000")
mlflow.set_experiment("churn-rf-mlops")
```

Then run:

```bash
python src/train.py
```

Compare runs in the MLflow UI (params: `n_estimators`, `max_depth`; metrics: `val_precision`, `val_recall`, `val_f1`).

---

## Threshold strategies

* **Recall-first**: maximize recall with constraint `precision ≥ PRECISION_MIN` (default 0.80). Good when missing a churner is costly.
* **Best F1**: balance precision & recall.

`src/evaluate.py` searches thresholds (0.05 → 0.95 by 0.05) and writes both winners to `metrics/val_metrics.json`.

> Option: set `BEST_THRESHOLD` in `src/config.py` or read from env in the API.

---

## Serving (FastAPI)

`api/app.py` loads `models/model.pkl` and `data/processed.csv` to align features.

### Run locally (dev)

```bash
uvicorn api.app:app --reload --port 8000
```

Docs: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

### Example requests (PowerShell)

**Single:**

```powershell
$body = @{ Gender="Male"; Age=45; Contract="Month-to-Month"; "Internet Service"="Yes"; "Monthly Charge"=85.5 } | ConvertTo-Json
Invoke-RestMethod -Uri "http://127.0.0.1:8000/predict" -Method Post -Body $body -ContentType "application/json"
```

**Batch:**

```powershell
$batch = @{ items = @(
  @{ Gender="Male"; Age=45; Contract="Month-to-Month"; "Internet Service"="Yes"; "Monthly Charge"=85.5 },
  @{ Gender="Female"; Age=70; Contract="Two Year"; "Internet Service"="Yes"; "Monthly Charge"=65.0 }
)} | ConvertTo-Json -Depth 5
Invoke-RestMethod -Uri "http://127.0.0.1:8000/predict_many" -Method Post -Body $batch -ContentType "application/json"
```

> The pipeline imputes missing values and handles unknown categories gracefully.

---

## Docker (portable serving)

Lightweight image for the API only.

### Dockerfile

```dockerfile
FROM python:3.12-slim
ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1 PIP_NO_CACHE_DIR=1
WORKDIR /app
COPY requirements.txt /app/
RUN pip install -r requirements.txt
COPY api /app/api
COPY models /app/models
COPY data/processed.csv /app/data/processed.csv
EXPOSE 8000
CMD ["uvicorn", "api.app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Build & run

```bash
docker build -t churn-api .
docker run -p 8000:8000 churn-api
```

Optional: set threshold at runtime

```bash
docker run -e BEST_THRESHOLD=0.55 -p 8000:8000 churn-api
```

Use volumes to avoid rebuild after updating model/CSV:

```bash
docker run -p 8000:8000 \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/data/processed.csv:/app/data/processed.csv \
  churn-api
```

---

## Tips & troubleshooting

* **PowerShell vs Bash**: Use `Invoke-RestMethod` or `curl.exe` on Windows; line continuation is `` ` `` (backtick) or `^`.
* **MLflow server errors on Windows**: prefer `mlflow server` (single process) with SQLite backend.
* **DVC overlap**: don’t track the same artifact both as a standalone `.dvc` and as a pipeline `outs`.
* **API errors**: check Uvicorn logs; ensure `models/model.pkl` & `data/processed.csv` are present.

---

## Roadmap 

* Add `params.yaml` + DVC paramization (`-S`) for sweeps
* Register best model in MLflow Model Registry
* Docker Hub publish + GitHub Actions for CI build
* Batch scoring CLI & scheduled evaluation
* Feature importance & data drift checks

---


## Acknowledgements

* scikit-learn, DVC, MLflow, FastAPI communities.
* Telco-like churn dataset used for demo purposes.
